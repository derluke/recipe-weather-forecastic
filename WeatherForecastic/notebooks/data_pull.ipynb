{"cells":[{"cell_type":"markdown","metadata":{},"source":["### This notebook will be automatically filled in with your parameters."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import subprocess\n","import sys\n","import os\n","import datetime\n","import json\n","from typing import List, Dict, Any, Optional, Union\n","import datarobot as dr\n","from datarobot.models.use_cases.utils import UseCaseLike\n","\n","\n","try:\n","    import openmeteo_requests\n","    import requests_cache\n","    import pandas as pd\n","    from retry_requests import retry\n","    import pytz\n","\n","except ImportError as e:\n","    print(\"Installing packages\")\n","    missing_packages = []\n","\n","    try:\n","        import openmeteo_requests\n","    except ImportError:\n","        missing_packages.append('openmeteo_requests')\n","\n","    try:\n","        import requests_cache\n","    except ImportError:\n","        missing_packages.append('requests_cache')\n","\n","    try:\n","        import pandas as pd\n","    except ImportError:\n","        missing_packages.append('pandas')\n","\n","    try:\n","        from retry_requests import retry\n","    except ImportError:\n","        missing_packages.append('retry_requests')\n","\n","    try:\n","        import pytz\n","    except ImportError:\n","        missing_packages.append('pytz')\n","\n","    if missing_packages:\n","        print(f\"Installing missing packages: {' '.join(missing_packages)}\")\n","        subprocess.check_call([sys.executable, '-m', 'pip', 'install'] + missing_packages)\n","\n","    # Try importing again after installation\n","    import openmeteo_requests\n","    import requests_cache\n","    import pandas as pd\n","    from retry_requests import retry\n","    import datetime\n","    import pytz\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_today_city_data(\n","        locations: List[Dict[str, float]], \n","        parameters: Dict[str, Any]\n",") -> pd.DataFrame:\n","\n","    # Setup the Open-Meteo API client with cache and retry on error\n","    cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n","    retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n","    openmeteo = openmeteo_requests.Client(session = retry_session)\n","\n","    # Make sure all required weather variables are listed here\n","    # The order of variables in hourly or daily is important to assign them correctly below\n","    url = \"https://api.open-meteo.com/v1/forecast\"\n","\n","    latitudes = [locations[city][\"Latitude\"] for city in locations]\n","    longitudes = [locations[city][\"Longitude\"] for city in locations]\n","    city_names = list(locations.keys())\n","\n","    parameters[\"past_days\"] = 1 # This should be tied to when the notebook scheduled to pull\n","    parameters[\"latitude\"] = latitudes\n","    parameters[\"longitude\"] = longitudes\n","\n","    responses = openmeteo.weather_api(url, params=parameters)\n","\n","    all_data = []\n","    for i, response in enumerate(responses):\n","        # TODO: Log this?\n","        print(f\"Gathered weather data from {city_names[i]}\")\n","\n","        # Process hourly data. The order of variables needs to be the same as requested.\n","        hourly = response.Hourly()\n","        hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()        \n","        hourly_precipitation_probability = hourly.Variables(1).ValuesAsNumpy()\n","        hourly_precipitation = hourly.Variables(2).ValuesAsNumpy()\n","        hourly_uv_index = hourly.Variables(3).ValuesAsNumpy()\n","\n","        timezone = pytz.timezone(response.Timezone())\n","        timestart = datetime.datetime.fromtimestamp(hourly.Time(), tz=timezone)\n","        timeend = datetime.datetime.fromtimestamp(hourly.TimeEnd(), tz=timezone)\n","\n","        hourly_data = {\n","            \"date\": pd.date_range(\n","                        start = timestart,\n","                        end = timeend,\n","                        freq = pd.Timedelta(seconds = hourly.Interval()),\n","                        inclusive = \"left\"\n","                    ).strftime('%Y-%m-%d %H:%M:%S'),\n","            \"temperature\": hourly_temperature_2m,\n","            \"uv_index\": hourly_uv_index,\n","            \"precipitation_probability\": hourly_precipitation_probability,\n","            \"precipitation\": hourly_precipitation,\n","            \"elevation\": response.Elevation(),\n","            \"longitude\": response.Latitude(), # make this an integer?\n","            \"latitude\": response.Longitude(), # make this an integer?\n","            \"city\": city_names[i]\n","        }\n","        all_data.append(pd.DataFrame(data=hourly_data))\n","\n","    hourly_dataframe = pd.concat(all_data, ignore_index=True)\n","    return hourly_dataframe"]},{"cell_type":"markdown","metadata":{},"source":["### Now that we have the dataframe, we append it to the existing data in our usecase."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def _check_if_dataset_exists(\n","        name: str, \n","        use_cases: Optional[UseCaseLike] = None\n",") -> Union[str, None]:\n","    \"\"\"\n","    Check if a dataset with the given name exists in your use case\n","    Returns:\n","        id (string) or None\n","    \"\"\"\n","    datasets = dr.Dataset.list(use_cases=use_cases)\n","    return next((dataset.id for dataset in datasets if dataset.name == name), None)\n","\n","locations = json.loads(os.environ[\"locations\"])\n","parameters = json.loads(os.environ[\"parameters\"])\n","\n","incoming_data = get_today_city_data(locations, parameters)\n","\n","modeling_dataset_name = os.environ[\"modeling_dataset_name\"]\n","use_case_id = os.environ[\"DATAROBOT_DEFAULT_USE_CASE\"]\n","\n","modeling_dataset_id = _check_if_dataset_exists(modeling_dataset_name, use_cases=use_case_id)\n","modeling_df = dr.Dataset.get(modeling_dataset_id).get_as_dataframe()\n","\n","new_data = pd.concat([modeling_df, incoming_data])\n","new_data['date'] = pd.to_datetime(new_data['date'])\n","\n","# Define a function to drop duplicates based on the 'date' column\n","def drop_duplicate_dates(group):\n","    return group.drop_duplicates(subset='date')\n","\n","# Apply the function to each group\n","new_data = new_data.groupby('city', group_keys=False).apply(drop_duplicate_dates)\n","\n","dr.Dataset.create_version_from_in_memory_data(modeling_dataset_id, new_data)"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
