{"cells": [{"cell_type": "code", "execution_count": 2, "id": "a26a631f-1fe3-4a75-a5a5-0e0db20e4ac6", "metadata": {"collapsed": false, "datarobot": {"disable_run": false, "execution_time_millis": 686, "hide_code": false, "hide_results": false, "language": "python"}, "jupyter": {"outputs_hidden": false, "source_hidden": false}, "scrolled": "auto"}, "outputs": [], "source": "import datetime as dt\nfrom typing import Union\n\nimport datarobot as dr\nfrom logzero import logger\nimport pandas as pd\nimport yaml\n\nfrom query_youtube import get_videos, compile_data, convert_to_dataframe\n\nCONFIG_FILE = \"config.yaml\"\nCREDENTIALS_FILE = \"credentials.yaml\"\nCURRENT_HOUR = pd.Timestamp.now().floor(\"h\")\n\nwith open(CONFIG_FILE, \"r\") as f:\n    config = yaml.load(f, Loader=yaml.FullLoader)\n\nwith open(CREDENTIALS_FILE, \"r\") as f:\n    credentials = yaml.load(f, Loader=yaml.FullLoader)\n    YOUTUBE_API_KEY = credentials[\"youtube_api_key\"]\n    CLIENT = dr.Client(endpoint=credentials[\"datarobot\"][\"endpoint\"], token=credentials[\"datarobot\"][\"api_token\"])\n"}, {"cell_type": "code", "execution_count": 3, "id": "8bf6f164-bf16-480c-a620-e2182705eaec", "metadata": {"collapsed": false, "datarobot": {"disable_run": false, "execution_time_millis": 13, "hide_code": false, "hide_results": false, "language": "python"}, "jupyter": {"outputs_hidden": false, "source_hidden": false}, "scrolled": "auto"}, "outputs": [], "source": "def check_if_dataset_exists(name: str) -> Union[str, None]:\n    \"\"\"\n    Check if a dataset with the given name exists in the AI Catalog\n    \"\"\"\n    datasets = dr.Dataset.list()\n    return next((dataset.id for dataset in datasets if dataset.name == name), None)\n\n\ndef write_new_dataset_to_catalog(df: pd.DataFrame, dataset_name) -> str:\n    \"\"\"\n    Write the metadata and stats dataframes to the AI Catalog\n    \"\"\"\n    dr_url = CLIENT.endpoint.split(\"/api\")[0]\n    catalog_id = dr.Dataset.create_from_in_memory_data(df, fname=dataset_name).id\n    logger.info(f\"Dataset {dataset_name} created: {dr_url + '/' + catalog_id}\")\n    return catalog_id\n\n\ndef write_new_version_to_catalog(stats_df: pd.DataFrame, dataset_id: str) -> None:\n    \"\"\"\n    Write a new version of a dataset to the AI Catalog\n    \"\"\"\n    dr_url = CLIENT.endpoint.split(\"/api\")[0]\n    current_stats = dr.Dataset.get(dataset_id).get_as_dataframe()\n    if max(pd.to_datetime(current_stats[\"AS_OF_DATE\"])) < CURRENT_HOUR:\n        full_stats = pd.concat([current_stats, stats_df]).reset_index(drop=True)\n        dr.Dataset.create_version_from_in_memory_data(dataset_id, full_stats)\n        logger.info(f\"New version of dataset created: {dr_url + '/' + dataset_id}\")\n    else:\n        logger.info(\"Dataset already up to date. Not writing new version.\")\n\n\ndef remove_old_dataset_versions(client: dr.client.RESTClientObject, dataset_id: str):\n    \"\"\"\n    Clean up dataset when it gets too big\n    \"\"\"\n    url = f\"datasets/{dataset_id}/versions/\"\n    dataset_versions = client.get(url).json()\n    logger.info(f\"Found {dataset_versions['count']} versions of {dataset_id}\")\n    if dataset_versions['count'] > 75:\n        sorted_versions = sorted(dataset_versions['data'], key=lambda x: pd.to_datetime(x['creationDate']))\n        for version in sorted_versions[:-50]:\n            url = f\"datasets/{dataset_id}/versions/{version['versionId']}\"\n            client.delete(url)\n        logger.info(f\"Deleted {dataset_versions['count'] - 50} versions of {dataset_id}\")"}, {"cell_type": "code", "execution_count": 5, "id": "6bd932d3-9f3d-4608-8e10-55baa2a52e11", "metadata": {"collapsed": false, "datarobot": {"disable_run": false, "execution_time_millis": 54286, "hide_code": false, "hide_results": false, "language": "python"}, "jupyter": {"outputs_hidden": false, "source_hidden": false}, "scrolled": "auto"}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["[I 240520 14:56:43 1618267384:16] Pulling data from playlist Endless Summer Vacation\n", "[I 240520 14:56:43 query_youtube:81] Pulled Youtube Metadata on Flowers\n", "[I 240520 14:56:43 query_youtube:81] Pulled Youtube Metadata on Jaded\n", "[I 240520 14:56:43 query_youtube:81] Pulled Youtube Metadata on Rose Colored Lenses\n", "[I 240520 14:56:43 query_youtube:81] Pulled Youtube Metadata on Used To Be Young\n", "[I 240520 14:56:43 query_youtube:81] Pulled Youtube Metadata on Thousand Miles\n", "[I 240520 14:56:43 query_youtube:81] Pulled Youtube Metadata on You\n", "[I 240520 14:56:43 query_youtube:81] Pulled Youtube Metadata on Handstand\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on River\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on Violet Chemistry\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on Muddy Feet\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on Wildcard\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on Island\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on Wonder Woman\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on Flowers (Demo)\n", "[I 240520 14:56:44 1618267384:16] Pulling data from playlist Plastic Hearts\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on WTF Do I Know\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on Plastic Hearts\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on Angels Like You\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on Prisoner\n", "[I 240520 14:56:44 query_youtube:81] Pulled Youtube Metadata on Gimme What I Want\n", "[I 240520 14:56:45 query_youtube:81] Pulled Youtube Metadata on Night Crawling\n", "[I 240520 14:56:45 query_youtube:81] Pulled Youtube Metadata on Midnight Sky\n", "[I 240520 14:56:45 query_youtube:81] Pulled Youtube Metadata on High\n", "[I 240520 14:56:45 query_youtube:81] Pulled Youtube Metadata on Hate Me\n", "[I 240520 14:56:45 query_youtube:81] Pulled Youtube Metadata on Bad Karma\n", "[I 240520 14:56:45 query_youtube:81] Pulled Youtube Metadata on Never Be Me\n", "[I 240520 14:56:45 query_youtube:81] Pulled Youtube Metadata on Golden G String\n", "[I 240520 14:56:45 query_youtube:81] Pulled Youtube Metadata on Edge of Midnight (Midnight Sky Remix)\n", "[I 240520 14:56:45 query_youtube:81] Pulled Youtube Metadata on Heart Of Glass (Live from the iHeart Festival)\n", "[I 240520 14:56:45 query_youtube:81] Pulled Youtube Metadata on Zombie (Live from the NIVA Save Our Stages Festival)\n", "[I 240520 14:57:35 3150602960:15] Dataset Miley metadata created: https://app.datarobot.com/664b64af656001b34bf830f3\n"]}], "source": "metadata_dataset_name= config['storage']['metadata']\nstats_dataset_name = config['storage']['statistics']\n\nstats_id = check_if_dataset_exists(stats_dataset_name)\nif stats_id is not None:\n    current_stats = dr.Dataset.get(stats_id).get_as_dataframe()\n    last_updated = max(pd.to_datetime(current_stats[\"AS_OF_DATE\"]))\nelse:\n    last_updated = dt.datetime.now() - dt.timedelta(weeks=1000)\n\nif last_updated == CURRENT_HOUR:\n    logger.info(\"Data already up to date. Not pulling new data.\")\nelse:\n    stats_all_df, metadata_all_df = pd.DataFrame(), pd.DataFrame()\n    for playlist in config[\"playlists\"]:\n        logger.info(f\"Pulling data from playlist {playlist['name']}\")\n        videos = get_videos(playlist['id'], YOUTUBE_API_KEY)\n        stats, metadata = compile_data(videos, YOUTUBE_API_KEY, CURRENT_HOUR)\n        stats_df, metadata_df = convert_to_dataframe(stats, metadata)\n        stats_all_df = pd.concat([stats_all_df, stats_df])\n        metadata_df[\"PLAYLIST_NAME\"] = playlist[\"name\"]\n        metadata_all_df = pd.concat([metadata_all_df, metadata_df])\n\n    metadata_id = check_if_dataset_exists(metadata_dataset_name)\n    if metadata_id is None:\n        write_new_dataset_to_catalog(metadata_all_df, metadata_dataset_name)\n\n    if stats_id is None:\n        write_new_dataset_to_catalog(stats_all_df, stats_dataset_name)\n    else:\n        write_new_version_to_catalog(stats_all_df, stats_id)\n        remove_old_dataset_versions(CLIENT, stats_id)\n"}, {"cell_type": "code", "execution_count": 0, "id": "d0123818-4e94-4efa-babe-915badcbf2eb", "metadata": {"collapsed": false, "datarobot": {"chart_settings": null, "custom_llm_metric_settings": null, "custom_metric_settings": null, "dataframe_view_options": null, "disable_run": false, "execution_time_millis": null, "hide_code": false, "hide_results": false, "language": "python"}, "jupyter": {"outputs_hidden": false, "source_hidden": false}, "scrolled": false}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}