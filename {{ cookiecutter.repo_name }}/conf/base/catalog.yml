# This is a registry of files that can be used as node inputs or for storing node outputs.
#
# When defining node inputs in the pipeline, reference a key from this yaml to indicate
# that the pipeline should map the file defined here to the node's input at runtime.
# Similarly, node outputs can be mapped and persisted to files defined in this yaml.
#
# Please see the Kedro Data Catalog documentation to learn more
# https://docs.kedro.org/en/stable/data/data_catalog.html

get_data_pipeline.time_series_data:
    type: pandas.CSVDataset
    filepath: data/outputs/time_series_data.csv
    
get_data_pipeline.metadata:
    type: pandas.CSVDataset
    filepath: data/outputs/metadata.csv

get_data_pipeline.use_case_id:
  type: text.TextDataset
  filepath: data/outputs/use_case_id.txt

deploy_forecast.use_case_id:
  type: text.TextDataset
  filepath: data/outputs/use_case_id.txt

deploy_forecast.dataset_id:
  type: text.TextDataset
  filepath: data/outputs/dataset_id.txt

project_id:
  type: text.TextDataset
  filepath: data/outputs/project_id.txt

# We store certain variables like these to ensure that certain nodes have run
#  before other nodes in the pipeline.
get_data_pipeline.metadataset_name:
  type: text.TextDataset
  filepath: data/outputs/metadataset_name.txt

get_data_pipeline.timeseries_dataset_name:
  type: text.TextDataset
  filepath: data/outputs/timeseries_dataset_name.txt